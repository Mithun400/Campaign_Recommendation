{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import numpy as np\nimport pandas as pd\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import Row\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom numpy.linalg import norm\nimport time\nfrom pyspark.sql.functions import split, explode,col\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline\n"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "line_item=['x'+str(i) for i in range(15)]\nimport random  \nimport string  \ndef specific_string(length):  \n    sample_string = 'pw y' # define teh specific string  \n    # define teh condition for random string  \n    result = ''.join((random.choice(sample_string)) for x in range(length))  \n    #print(\" Randomly generated string is: \", result)  \n    return result\nKW=[]\nfor i in range(len(line_item)):\n    KW.append([])\n    for j in range(5):\n        KW[i].append(specific_string(np.random.randint(2,5)))\ndef specific_user_segment():  \n    sample_string = 'segment' # define teh specific string\n    idx=np.random.randint(0,50)\n    return sample_string+str(idx)\nUS=[]\nfor i in range(len(line_item)):\n    US.append([])\n    for j in range(3):\n        US[i].append(specific_user_segment())\nadvertiser_id=[np.random.randint(0,6) for _ in range(len(line_item))]\ncamp_category=['food']*10+['electric']*5\ndf_kw=pd.DataFrame({\n    'line_item_id':line_item,\n    'keywords':KW,\n    'advertiser_id':advertiser_id,\n    'camp_category':camp_category\n})\ndf_kw_exp=df_kw.explode('keywords')\ndf_us=pd.DataFrame({\n    'line_item_id':line_item,\n    'segments':US,\n    'advertiser_id':advertiser_id,\n    'camp_category':camp_category\n})\n\ndf_us_exp=df_us.explode('segments')\nuq_kw=list(df_kw_exp.keywords.unique())\nreach=[np.random.randint(1000,5000) for _ in range(len(uq_kw))]\nuser_reach_KW=pd.DataFrame({\n    'keywords':uq_kw,\n    'user_reach':reach\n})\nuq_us=list(df_us_exp.segments.unique())\nreach=[np.random.randint(1000,5000) for _ in range(len(uq_us))]\nuser_reach_US=pd.DataFrame({\n    'user_segment':uq_us,\n    'user_reach':reach\n})"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "def fn1(x):\n    return (''.join([i if 32 < ord(i) < 126 else \" \" for i in x]))\n\ndef fn2(x):\n    return (''.join([i if i not in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+\" else \" \" for i in x]))\n\ndef fn3(x):\n    return (''.join([i if i not in '!@#$%^&*()[]{};:,/<>?\\|`~-=_+\"\"\\n' else \" \" for i in x]))\ndef itemperse(d,char,dedup):\n    idx=d[char]\n    res=np.zeros(len(dedup))\n    res[idx]=1\n    return res\n\ndef preprocessing_kw(df,df_user_reach):\n    data=list(df['keywords'])\n    all_sentences = [l.split('\\t')[0] for l in data]\n    all_sentences = [fn1(sentence) for sentence in all_sentences]\n    all_sentences = [fn2(sentence) for sentence in all_sentences]\n    all_sentences = [sentence.lower() for sentence in all_sentences]\n    all_sentences = [sentence.strip() for sentence in all_sentences]\n    preprocessed_kw={data[i]:all_sentences[i] for i in range(len(data))}### user reach extraction\n    \n    df_user_reach['preprocessed_kw']=df_user_reach['keywords'].map(preprocessed_kw)\n    df_user_reach=df_user_reach.groupby(['preprocessed_kw']).agg({'user_reach':'sum'}).round(2)\n\n    \n    df['kw_id']=df['keywords'].map(preprocessed_kw)\n    df_item_user=df.groupby(['line_item_id','kw_id']).size().reset_index()[['line_item_id','kw_id']]\n    df_item_user['rating']=1\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    sparkDF=spark.createDataFrame(df_item_user) \n    indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(sparkDF.columns)-set(['rating'])) ]\n    pipeline = Pipeline(stages=indexer)\n    transformed = pipeline.fit(sparkDF).transform(sparkDF)\n    #transformed=transformed.select(['line_item_id_index','kw_id_index','rating'])\n    \n    md=transformed.select(transformed['line_item_id'],transformed['line_item_id_index'],transformed['kw_id'],transformed['kw_id_index'])\n    md=md.toPandas()\n    dict1 =dict(zip(md['line_item_id_index'],md['line_item_id']))\n    dict2=dict(zip(md['kw_id_index'],md['kw_id']))\n\n\n    return transformed,df_user_reach,preprocessed_kw,dict1,dict2\ndef preprocessing_kw_cs(df,df_user_reach):\n    data=list(df['keywords'])\n    all_sentences = [l.split('\\t')[0] for l in data]\n    all_sentences = [fn1(sentence) for sentence in all_sentences]\n    all_sentences = [fn2(sentence) for sentence in all_sentences]\n    all_sentences = [sentence.lower() for sentence in all_sentences]\n    all_sentences = [sentence.strip() for sentence in all_sentences]\n    preprocessed_kw={data[i]:all_sentences[i] for i in range(len(data))}### user reach extraction\n    \n    df_user_reach['preprocessed_kw']=df_user_reach['keywords'].map(preprocessed_kw)\n    df_user_reach=df_user_reach.groupby(['preprocessed_kw']).agg({'user_reach':'sum'}).round(2)\n\n    \n    df['kw_id']=df['keywords'].map(preprocessed_kw)\n    df_item_user=df.groupby(['advertiser_id','kw_id']).size().reset_index()[['advertiser_id','kw_id']]\n    df_item_user['rating']=1\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    sparkDF=spark.createDataFrame(df_item_user) \n    indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(sparkDF.columns)-set(['rating'])) ]\n    pipeline = Pipeline(stages=indexer)\n    transformed = pipeline.fit(sparkDF).transform(sparkDF)\n    #transformed=transformed.select(['line_item_id_index','kw_id_index','rating'])\n    \n    md=transformed.select(transformed['advertiser_id'],transformed['advertiser_id_index'],transformed['kw_id'],transformed['kw_id_index'])\n    md=md.toPandas()\n    dict1 =dict(zip(md['advertiser_id_index'],md['advertiser_id']))\n    dict2=dict(zip(md['kw_id_index'],md['kw_id']))\n\n    return transformed,df_user_reach,preprocessed_kw,dict1,dict2\n"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "def preprocessing_us(df,df_user_reach):\n    df_item_user=df.groupby(['line_item_id','segments']).size().reset_index()[['line_item_id','segments']]\n    df_item_user['rating']=1\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    sparkDF=spark.createDataFrame(df_item_user) \n    indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(sparkDF.columns)-set(['rating'])) ]\n    pipeline = Pipeline(stages=indexer)\n    transformed = pipeline.fit(sparkDF).transform(sparkDF)\n    #transformed=transformed.select(['line_item_id_index','kw_id_index','rating'])\n    \n    md=transformed.select(transformed['line_item_id'],transformed['line_item_id_index'],transformed['segments'],transformed['segments_index'])\n    md=md.toPandas()\n    dict1 =dict(zip(md['line_item_id_index'],md['line_item_id']))\n    dict2=dict(zip(md['segments_index'],md['segments']))\n    return transformed,df_user_reach,dict1,dict2\ndef preprocessing_us_cs(df,df_user_reach):\n    \n    df_item_user=df.groupby(['advertiser_id','segments']).size().reset_index()[['advertiser_id','segments']]\n    df_item_user['rating']=1\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    sparkDF=spark.createDataFrame(df_item_user) \n    indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(sparkDF.columns)-set(['rating'])) ]\n    pipeline = Pipeline(stages=indexer)\n    transformed = pipeline.fit(sparkDF).transform(sparkDF)\n    #transformed=transformed.select(['line_item_id_index','kw_id_index','rating'])\n    \n    md=transformed.select(transformed['advertiser_id'],transformed['advertiser_id_index'],transformed['segments'],transformed['segments_index'])\n    md=md.toPandas()\n    dict1 =dict(zip(md['advertiser_id_index'],md['advertiser_id']))\n    dict2=dict(zip(md['segments_index'],md['segments']))\n\n    return transformed,df_user_reach,dict1,dict2"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": "def targeting_tactic_reco_kw(df_kw_exp,user_reach_KW,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,camp_category='food',advertiser_id=2):\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    df_kw_exp=df_kw_exp.loc[df_kw_exp['camp_category']==camp_category]\n    if line_item_id not in list(df_kw_exp['line_item_id'].unique()):\n        return targeting_tactic_reco_cold_kw(df_kw_exp,user_reach_KW,number_of_impression=number_of_impression,line_item_id=line_item_id,average_freq_cap=average_freq_cap,camp_category=camp_category,advertiser_id=advertiser_id)\n    \n    df_kwx,ur_kw,preprocessed_kw,d_lin_item,d_kw=preprocessing_kw(df_kw_exp,user_reach_KW)\n    d_reach={ur_kw.index[i]:ur_kw['user_reach'][i] for i in range(ur_kw.shape[0])}\n    (training,test)=df_kwx.randomSplit([0.8, 0.2])\n    als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"line_item_id_index\",itemCol=\"kw_id_index\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n    model=als.fit(training)\n    \n    evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n    predictions=model.transform(test)\n    rmse=evaluator.evaluate(predictions)\n    print(\"RMSE=\"+str(rmse))\n    \n    recs=model.recommendForAllUsers(15).toPandas()\n    nrecs=recs.recommendations.apply(pd.Series) \\\n                .merge(recs, right_index = True, left_index = True) \\\n                .drop([\"recommendations\"], axis = 1) \\\n                .melt(id_vars = ['line_item_id_index'], value_name = \"recommendation\") \\\n                .drop(\"variable\", axis = 1) \\\n                .dropna() \n    nrecs=nrecs.sort_values('line_item_id_index')\n    nrecs=pd.concat([nrecs['recommendation'].apply(pd.Series), nrecs['line_item_id_index']], axis = 1)\n    nrecs.columns = [\n            'kw_id_index',\n            'Rating',\n            'line_item_id_index'\n         ]\n    nrecs['line_item_id']=nrecs['line_item_id_index'].map(d_lin_item)\n    nrecs['kw_id']=nrecs['kw_id_index'].map(d_kw)\n    nrecs=nrecs.sort_values('line_item_id')\n    nrecs.reset_index(drop=True, inplace=True)\n    new=nrecs[['line_item_id','kw_id','Rating']]\n    \n    new['User_reach']=new['kw_id'].map(d_reach)\n    df_kw_exp['preprocessed_kw']=df_kw_exp['keywords'].map(preprocessed_kw)\n    existed_kw=list(df_kw_exp.loc[df_kw_exp['line_item_id']==line_item_id]['preprocessed_kw'].values)\n    \n    reco_camp_id=new[(new['line_item_id']==line_item_id)].sort_values('User_reach',ascending=False).reset_index()[['line_item_id','kw_id','Rating','User_reach']]\n    \n    reco_camp_id=reco_camp_id[~reco_camp_id['kw_id'].isin(existed_kw)]\n    reco_camp_id['impression_provided']=reco_camp_id['User_reach']*average_freq_cap\n    \n    reco_camp_id['cum_impression'] = reco_camp_id.impression_provided.cumsum()\n    #reco_camp_id=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression]\n    reco_camp_id=reco_camp_id.reset_index()[['line_item_id','kw_id','Rating','impression_provided','cum_impression']]\n    idx=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression].index[-1]\n    if reco_camp_id['cum_impression'][idx]==number_of_impression:\n        return reco_camp_id.loc[:str(int(idx))]\n    return reco_camp_id.loc[:str(int(idx)+1)] if reco_camp_id.shape[0]>idx else reco_camp_id.loc[:str(int(idx))]\ndef targeting_tactic_reco_cold_kw(df_kw_exp,user_reach_KW,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,camp_category='food',advertiser_id=2):\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()    \n    if advertiser_id not in list(df_kw_exp['advertiser_id'].unique()):\n        print('No recommendation can be provided since Advertiser has not past campaigns history and also line item is new campaign with no data')\n        return\n        \n    print('Line item id: ',line_item_id,' has no historical data and thus recommending based on the advertiser past campaigns data')\n    df_kwx,ur_kw,preprocessed_kw,d_lin_item,d_kw=preprocessing_kw_cs(df_kw_exp,user_reach_KW)\n    d_reach={ur_kw.index[i]:ur_kw['user_reach'][i] for i in range(ur_kw.shape[0])}\n    (training,test)=df_kwx.randomSplit([0.8, 0.2])\n    als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"advertiser_id_index\",itemCol=\"kw_id_index\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n    model=als.fit(training)\n    \n    evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n    predictions=model.transform(test)\n    rmse=evaluator.evaluate(predictions)\n    print(\"RMSE=\"+str(rmse))\n    \n    recs=model.recommendForAllUsers(15).toPandas()\n    nrecs=recs.recommendations.apply(pd.Series) \\\n                .merge(recs, right_index = True, left_index = True) \\\n                .drop([\"recommendations\"], axis = 1) \\\n                .melt(id_vars = ['advertiser_id_index'], value_name = \"recommendation\") \\\n                .drop(\"variable\", axis = 1) \\\n                .dropna() \n    nrecs=nrecs.sort_values('advertiser_id_index')\n    nrecs=pd.concat([nrecs['recommendation'].apply(pd.Series), nrecs['advertiser_id_index']], axis = 1)\n    nrecs.columns = [\n            'kw_id_index',\n            'Rating',\n            'advertiser_id_index'\n         ]\n    nrecs['advertiser_id']=nrecs['advertiser_id_index'].map(d_lin_item)\n    nrecs['kw_id']=nrecs['kw_id_index'].map(d_kw)\n    nrecs=nrecs.sort_values('advertiser_id')\n    nrecs.reset_index(drop=True, inplace=True)\n    new=nrecs[['advertiser_id','kw_id','Rating']]\n    \n    new['User_reach']=new['kw_id'].map(d_reach)\n    df_kw_exp['preprocessed_kw']=df_kw_exp['keywords'].map(preprocessed_kw)\n    \n    reco_camp_id=new[(new['advertiser_id']==advertiser_id)].sort_values('User_reach',ascending=False).reset_index()[['advertiser_id','kw_id','Rating','User_reach']]\n    \n    reco_camp_id['impression_provided']=reco_camp_id['User_reach']*average_freq_cap\n    \n    reco_camp_id['cum_impression'] = reco_camp_id.impression_provided.cumsum()\n    #reco_camp_id=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression]\n    \n    reco_camp_id=reco_camp_id.reset_index()[['advertiser_id','kw_id','Rating','impression_provided','cum_impression']]\n    idx=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression].index[-1]\n    if reco_camp_id['cum_impression'][idx]==number_of_impression:\n        return reco_camp_id.loc[:str(int(idx))]\n    return reco_camp_id.loc[:str(int(idx)+1)] if reco_camp_id.shape[0]>idx else reco_camp_id.loc[:str(int(idx))]\n"}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": "def targeting_tactic_reco_us(df_us_exp,user_reach_US,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,camp_category='food',advertiser_id=2):\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()\n    \n    df_us_exp=df_us_exp.loc[df_us_exp['camp_category']==camp_category]\n    if line_item_id not in list(df_us_exp['line_item_id'].unique()):\n        return targeting_tactic_reco_cold_us(df_us_exp,user_reach_US,number_of_impression=number_of_impression,line_item_id=line_item_id,average_freq_cap=average_freq_cap,camp_category=camp_category,advertiser_id=advertiser_id)\n    \n    df_usx,ur_us,d_lin_item,d_us=preprocessing_us(df_us_exp,user_reach_US)\n    d_reach={ur_us['user_segment'][i]:ur_us['user_reach'][i] for i in range(ur_us.shape[0])}\n\n    (training,test)=df_usx.randomSplit([0.8, 0.2])\n    als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"line_item_id_index\",itemCol=\"segments_index\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n    model=als.fit(training)\n    \n    evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n    predictions=model.transform(test)\n    rmse=evaluator.evaluate(predictions)\n    print(\"RMSE=\"+str(rmse))\n    \n    recs=model.recommendForAllUsers(15).toPandas()\n    nrecs=recs.recommendations.apply(pd.Series) \\\n                .merge(recs, right_index = True, left_index = True) \\\n                .drop([\"recommendations\"], axis = 1) \\\n                .melt(id_vars = ['line_item_id_index'], value_name = \"recommendation\") \\\n                .drop(\"variable\", axis = 1) \\\n                .dropna() \n    nrecs=nrecs.sort_values('line_item_id_index')\n    nrecs=pd.concat([nrecs['recommendation'].apply(pd.Series), nrecs['line_item_id_index']], axis = 1)\n    nrecs.columns = [\n            'segments_index',\n            'Rating',\n            'line_item_id_index'\n         ]\n    nrecs['line_item_id']=nrecs['line_item_id_index'].map(d_lin_item)\n    nrecs['segments']=nrecs['segments_index'].map(d_us)\n    nrecs=nrecs.sort_values('line_item_id')\n    nrecs.reset_index(drop=True, inplace=True)\n    new=nrecs[['line_item_id','segments','Rating']]\n    \n    new['User_reach']=new['segments'].map(d_reach)\n    existed_us=list(df_us_exp.loc[df_us_exp['line_item_id']==line_item_id]['segments'].values)\n    \n    reco_camp_id=new[(new['line_item_id']==line_item_id)].sort_values('User_reach',ascending=False).reset_index()[['line_item_id','segments','Rating','User_reach']]\n    \n    reco_camp_id=reco_camp_id[~reco_camp_id['segments'].isin(existed_us)]\n    reco_camp_id['impression_provided']=reco_camp_id['User_reach']*average_freq_cap\n    \n    reco_camp_id['cum_impression'] = reco_camp_id.impression_provided.cumsum()\n    #reco_camp_id=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression]\n    \n    reco_camp_id=reco_camp_id.reset_index()[['line_item_id','segments','Rating','impression_provided','cum_impression']]\n    idx=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression].index[-1]\n    if reco_camp_id['cum_impression'][idx]==number_of_impression:\n        return reco_camp_id.loc[:str(int(idx))]\n    return reco_camp_id.loc[:str(int(idx)+1)] if reco_camp_id.shape[0]>idx else reco_camp_id.loc[:str(int(idx))]\n\ndef targeting_tactic_reco_cold_us(df_us_exp,user_reach_US,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,camp_category='food',advertiser_id=2):\n    spark = SparkSession \\\n    .builder \\\n    .master(\"local\") \\\n    .appName(\"Protob Conversion to Parquet\") \\\n    .getOrCreate()    \n    if advertiser_id not in list(df_us_exp['advertiser_id'].unique()):\n        print('No recommendation can be provided since Advertiser has not past campaigns history and also line item is new campaign with no data')\n        return\n        \n    print('Line item id: ',line_item_id,' has no historical data and thus recommending based on the advertiser past campaigns data')\n    df_usx,ur_us,d_lin_item,d_us=preprocessing_us_cs(df_us_exp,user_reach_US)\n#     d_reach={ur_us.index[i]:ur_us['user_reach'][i] for i in range(ur_us.shape[0])}\n    d_reach={ur_us['user_segment'][i]:ur_us['user_reach'][i] for i in range(ur_us.shape[0])}\n    (training,test)=df_usx.randomSplit([0.8, 0.2])\n    als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"advertiser_id_index\",itemCol=\"segments_index\",ratingCol=\"rating\",coldStartStrategy=\"drop\",nonnegative=True)\n    model=als.fit(training)\n    \n    evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n    predictions=model.transform(test)\n    rmse=evaluator.evaluate(predictions)\n    print(\"RMSE=\"+str(rmse))\n    \n    recs=model.recommendForAllUsers(15).toPandas()\n    nrecs=recs.recommendations.apply(pd.Series) \\\n                .merge(recs, right_index = True, left_index = True) \\\n                .drop([\"recommendations\"], axis = 1) \\\n                .melt(id_vars = ['advertiser_id_index'], value_name = \"recommendation\") \\\n                .drop(\"variable\", axis = 1) \\\n                .dropna() \n    nrecs=nrecs.sort_values('advertiser_id_index')\n    nrecs=pd.concat([nrecs['recommendation'].apply(pd.Series), nrecs['advertiser_id_index']], axis = 1)\n    nrecs.columns = [\n            'segments_index',\n            'Rating',\n            'advertiser_id_index'\n         ]\n    nrecs['advertiser_id']=nrecs['advertiser_id_index'].map(d_lin_item)\n    nrecs['segments']=nrecs['segments_index'].map(d_us)\n    nrecs=nrecs.sort_values('advertiser_id')\n    nrecs.reset_index(drop=True, inplace=True)\n    new=nrecs[['advertiser_id','segments','Rating']]\n    \n    new['User_reach']=new['segments'].map(d_reach)    \n    \n    reco_camp_id=new[(new['advertiser_id']==advertiser_id)].sort_values('User_reach',ascending=False).reset_index()[['advertiser_id','segments','Rating','User_reach']]\n    \n    reco_camp_id['impression_provided']=reco_camp_id['User_reach']*average_freq_cap\n    \n    reco_camp_id['cum_impression'] = reco_camp_id.impression_provided.cumsum()\n    #reco_camp_id=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression]\n\n    reco_camp_id=reco_camp_id.reset_index()[['advertiser_id','segments','Rating','impression_provided','cum_impression']]\n    idx=reco_camp_id.loc[reco_camp_id['cum_impression'] <= number_of_impression].index[-1]\n    if reco_camp_id['cum_impression'][idx]==number_of_impression:\n        return reco_camp_id.loc[:str(int(idx))]\n    return reco_camp_id.loc[:str(int(idx)+1)] if reco_camp_id.shape[0]>idx else reco_camp_id.loc[:str(int(idx))]"}, {"cell_type": "markdown", "metadata": {}, "source": "Lets try to recommend keywords for KT targeting for the line item id: x0 and required number of impression= 20k for the advertiser id: 1 with campaign category=food"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"}, {"name": "stdout", "output_type": "stream", "text": "RMSE=0.14369827508926392\n"}, {"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_item_id</th>\n      <th>kw_id</th>\n      <th>Rating</th>\n      <th>impression_provided</th>\n      <th>cum_impression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>x0</td>\n      <td>wp</td>\n      <td>0.911724</td>\n      <td>7320</td>\n      <td>7320</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>x0</td>\n      <td>ypy</td>\n      <td>0.914079</td>\n      <td>4745</td>\n      <td>12065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>x0</td>\n      <td>yw</td>\n      <td>0.887980</td>\n      <td>4021</td>\n      <td>16086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>x0</td>\n      <td>py</td>\n      <td>0.837598</td>\n      <td>3717</td>\n      <td>19803</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>x0</td>\n      <td>wy</td>\n      <td>0.874359</td>\n      <td>3589</td>\n      <td>23392</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  line_item_id kw_id    Rating  impression_provided  cum_impression\n0           x0    wp  0.911724                 7320            7320\n1           x0   ypy  0.914079                 4745           12065\n2           x0    yw  0.887980                 4021           16086\n3           x0    py  0.837598                 3717           19803\n4           x0    wy  0.874359                 3589           23392"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "reco_x0=targeting_tactic_reco_kw(df_kw_exp,user_reach_KW,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,advertiser_id=1)\nreco_x0"}, {"cell_type": "markdown", "metadata": {}, "source": "Lets try to recommend keywords for KT targeting for the line item id: x31  which is a cold start problem and required number of impression= 20k for the advertiser id: 1 with campaign category=food"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Line item id:  x31  has no historical data and thus recommending based on the advertiser past campaigns data\n"}, {"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"}, {"name": "stdout", "output_type": "stream", "text": "RMSE=0.3538964852108103\n"}, {"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>advertiser_id</th>\n      <th>kw_id</th>\n      <th>Rating</th>\n      <th>impression_provided</th>\n      <th>cum_impression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>yy</td>\n      <td>0.911359</td>\n      <td>11839</td>\n      <td>11839</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>w</td>\n      <td>0.929862</td>\n      <td>8019</td>\n      <td>19858</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ww</td>\n      <td>0.863512</td>\n      <td>4505</td>\n      <td>24363</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   advertiser_id kw_id    Rating  impression_provided  cum_impression\n0              2    yy  0.911359                11839           11839\n1              2     w  0.929862                 8019           19858\n2              2    ww  0.863512                 4505           24363"}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "reco_x0=targeting_tactic_reco_kw(df_kw_exp,user_reach_KW,number_of_impression=20000,line_item_id='x31',average_freq_cap=1,advertiser_id=2)\nreco_x0"}, {"cell_type": "markdown", "metadata": {}, "source": "Lets try to recommend keywords for BT targeting for the line item id: x0 and required number of impression= 20k for the advertiser id: 1 with campaign category=food"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "reco_x0=targeting_tactic_reco_us(df_us_exp,user_reach_US,number_of_impression=20000,line_item_id='x0',average_freq_cap=1,camp_category='food',advertiser_id=2)\nreco_x0"}, {"cell_type": "markdown", "metadata": {}, "source": "Lets try to recommend keywords for BT targeting for the line item id: x0 and required number of impression= 20k for the advertiser id: 1 with campaign category=food"}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Line item id:  x10  has no historical data and thus recommending based on the advertiser past campaigns data\nRMSE=0.18913304805755615\n"}, {"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>advertiser_id</th>\n      <th>segments</th>\n      <th>Rating</th>\n      <th>impression_provided</th>\n      <th>cum_impression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>segment41</td>\n      <td>0.911195</td>\n      <td>4741</td>\n      <td>4741</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>segment20</td>\n      <td>0.866845</td>\n      <td>4584</td>\n      <td>9325</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>segment33</td>\n      <td>0.909903</td>\n      <td>3868</td>\n      <td>13193</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>segment17</td>\n      <td>0.810867</td>\n      <td>3784</td>\n      <td>16977</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>segment43</td>\n      <td>0.911195</td>\n      <td>3491</td>\n      <td>20468</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   advertiser_id   segments    Rating  impression_provided  cum_impression\n0              2  segment41  0.911195                 4741            4741\n1              2  segment20  0.866845                 4584            9325\n2              2  segment33  0.909903                 3868           13193\n3              2  segment17  0.810867                 3784           16977\n4              2  segment43  0.911195                 3491           20468"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "reco_x0=targeting_tactic_reco_us(df_us_exp,user_reach_US,number_of_impression=20000,line_item_id='x10',average_freq_cap=1,camp_category='food',advertiser_id=2)\nreco_x0"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}}, "nbformat": 4, "nbformat_minor": 2}